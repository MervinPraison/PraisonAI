name: Quick Validation Tests

on: [push, pull_request]

jobs:
  quick-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: 3.11

    - name: Install UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: |
        uv pip install --system ."[ui,gradio,api,agentops,google,openai,anthropic,cohere,chat,code,realtime,call,crewai,autogen]"
        uv pip install --system duckduckgo_search
        uv pip install --system pytest pytest-asyncio pytest-cov

    - name: Set environment variables
      run: |
        echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY || 'sk-test-key-for-github-actions-testing-only-not-real' }}" >> $GITHUB_ENV
        echo "OPENAI_API_BASE=${{ secrets.OPENAI_API_BASE || 'https://api.openai.com/v1' }}" >> $GITHUB_ENV
        echo "OPENAI_MODEL_NAME=${{ secrets.OPENAI_MODEL_NAME || 'gpt-4o-mini' }}" >> $GITHUB_ENV
        echo "LOGLEVEL=DEBUG" >> $GITHUB_ENV
        echo "PYTHONPATH=${{ github.workspace }}/src/praisonai-agents:$PYTHONPATH" >> $GITHUB_ENV

    - name: Debug API Key Status
      run: |
        echo "ğŸ” Checking API key availability..."
        if [ -n "${{ secrets.OPENAI_API_KEY }}" ]; then
          echo "âœ… GitHub secret OPENAI_API_KEY is available"
          echo "ğŸ”‘ API key starts with: $(echo "$OPENAI_API_KEY" | cut -c1-7)..."
        else
          echo "âš ï¸ GitHub secret OPENAI_API_KEY is NOT set - using fallback"
          echo "ğŸ”‘ Using fallback key: sk-test-key..."
        fi
        echo "ğŸŒ API Base: $OPENAI_API_BASE"
        echo "ğŸ¤– Model: $OPENAI_MODEL_NAME"
        echo "ğŸ› Log Level: $LOGLEVEL"
        echo "ğŸ“Š Environment Check:"
        echo "  - OPENAI_API_KEY length: ${#OPENAI_API_KEY}"
        echo "  - OPENAI_API_BASE: $OPENAI_API_BASE"
        echo "  - OPENAI_MODEL_NAME: $OPENAI_MODEL_NAME"
        echo "  - LOGLEVEL: $LOGLEVEL"

    - name: Debug Python Environment Variables
      run: |
        python -c "
        import os
        print('ğŸ Python Environment Variable Check:')
        api_key = os.environ.get('OPENAI_API_KEY', 'NOT_SET')
        if api_key != 'NOT_SET':
            print(f'  âœ… OPENAI_API_KEY: {api_key[:7]}... (length: {len(api_key)})')
        else:
            print('  âŒ OPENAI_API_KEY: NOT_SET')
        print(f'  ğŸŒ OPENAI_API_BASE: {os.environ.get(\"OPENAI_API_BASE\", \"NOT_SET\")}')
        print(f'  ğŸ¤– OPENAI_MODEL_NAME: {os.environ.get(\"OPENAI_MODEL_NAME\", \"NOT_SET\")}')
        print(f'  ğŸ“‹ All OPENAI env vars:')
        for key, value in os.environ.items():
            if key.startswith('OPENAI'):
                print(f'    {key}: {value[:10] if len(value) > 10 else value}...')
        "

    - name: Find Researcher Role Source
      run: |
        echo "ğŸ” Hunting for the mysterious 'Researcher' role..."
        python -c "
        import os
        import yaml
        import glob
        
        print('ğŸ“‹ Searching for Researcher role in all YAML files:')
        yaml_files = glob.glob('tests/*.yaml')
        
        for yaml_file in yaml_files:
            try:
                with open(yaml_file, 'r') as f:
                    config = yaml.safe_load(f)
                
                # Check if any role contains 'researcher'
                roles = config.get('roles', {})
                for role_key, role_data in roles.items():
                    role_name = role_data.get('role', '')
                    if 'researcher' in role_key.lower() or 'researcher' in role_name.lower():
                        print(f'  ğŸ¯ FOUND in {yaml_file}:')
                        print(f'    Framework: {config.get(\"framework\", \"NOT_SET\")}')
                        print(f'    Role key: {role_key}')
                        print(f'    Role name: {role_name}')
                        print(f'    All roles: {list(roles.keys())}')
                        print()
            except Exception as e:
                print(f'  âŒ Error reading {yaml_file}: {e}')
        
        print('ğŸ” Checking for default configurations...')
        # Check if there are any default configs or hardcoded roles
        try:
            import praisonai
            print(f'  PraisonAI package location: {praisonai.__file__}')
            
            # Check if there are any example YAML files in the package
            package_dir = os.path.dirname(praisonai.__file__)
            for root, dirs, files in os.walk(package_dir):
                for file in files:
                    if file.endswith(('.yaml', '.yml')):
                        file_path = os.path.join(root, file)
                        print(f'  ğŸ“ Found YAML in package: {file_path}')
        except Exception as e:
            print(f'  âŒ Error checking package: {e}')
        "
      continue-on-error: true

    - name: Trace AutoGen Execution Path
      run: |
        echo "ğŸ” Tracing AutoGen execution to find where it diverges..."
        python -c "
        import os
        import sys
        sys.path.insert(0, '.')
        
        try:
            from praisonai import PraisonAI
            from praisonai.agents_generator import AgentsGenerator
            
            # Test the exact execution path
            print('ğŸ¯ Testing AutoGen execution path:')
            
            praisonai = PraisonAI(agent_file='tests/autogen-agents.yaml')
            print(f'  1. PraisonAI framework: \"{praisonai.framework}\"')
            
            agents_gen = AgentsGenerator(
                agent_file='tests/autogen-agents.yaml',
                framework=praisonai.framework,
                config_list=praisonai.config_list
            )
            print(f'  2. AgentsGenerator framework: \"{agents_gen.framework}\"')
            
            # Load the YAML to check what it contains
            import yaml
            with open('tests/autogen-agents.yaml', 'r') as f:
                config = yaml.safe_load(f)
            
            framework = agents_gen.framework or config.get('framework')
            print(f'  3. Final framework decision: \"{framework}\"')
            print(f'  4. Available frameworks:')
            
            # Check framework availability
            try:
                import autogen
                print(f'    âœ… AutoGen available')
            except ImportError:
                print(f'    âŒ AutoGen NOT available')
                
            try:
                from praisonaiagents import Agent
                print(f'    âœ… PraisonAI agents available')
            except ImportError:
                print(f'    âŒ PraisonAI agents NOT available')
                
            try:
                from crewai import Agent
                print(f'    âœ… CrewAI available')
            except ImportError:
                print(f'    âŒ CrewAI NOT available')
            
            print(f'  5. Roles in YAML: {list(config.get(\"roles\", {}).keys())}')
            
            # Now test the actual framework execution
            if framework == 'autogen':
                print(f'  6. âœ… Should execute _run_autogen')
            elif framework == 'praisonai':
                print(f'  6. âŒ Would execute _run_praisonai (WRONG!)')
            else:
                print(f'  6. âŒ Would execute _run_crewai (DEFAULT FALLBACK)')
                
        except Exception as e:
            print(f'âŒ Error tracing execution: {e}')
            import traceback
            traceback.print_exc()
        "
      continue-on-error: true

    - name: Debug YAML Loading and Roles
      run: |
        echo "ğŸ” Tracing YAML file loading and role creation..."
        python -c "
        import os
        import sys
        import yaml
        sys.path.insert(0, '.')
        
        print('ğŸ“ Available YAML files in tests/:')
        import glob
        yaml_files = glob.glob('tests/*.yaml')
        for f in yaml_files:
            print(f'  {f}')
        
        print()
        print('ğŸ“‹ Content of autogen-agents.yaml:')
        with open('tests/autogen-agents.yaml', 'r') as f:
            config = yaml.safe_load(f)
        print(f'  Framework: {config.get(\"framework\")}')
        print(f'  Topic: {config.get(\"topic\")}')
        print(f'  Roles: {list(config.get(\"roles\", {}).keys())}')
        for role_key, role_data in config.get('roles', {}).items():
            print(f'    {role_key} -> {role_data.get(\"role\", \"NO_ROLE\")}')
        
        print()
        print('ğŸ” Checking if execution uses a different YAML:')
        
        # Check other YAML files for 'Researcher' role
        for yaml_file in yaml_files:
            try:
                with open(yaml_file, 'r') as f:
                    test_config = yaml.safe_load(f)
                roles = test_config.get('roles', {})
                for role_key, role_data in roles.items():
                    if 'researcher' in role_key.lower() or 'researcher' in role_data.get('role', '').lower():
                        print(f'  ğŸ¯ FOUND Researcher in {yaml_file}!')
                        print(f'    Framework: {test_config.get(\"framework\")}')
                        print(f'    Role key: {role_key} -> {role_data.get(\"role\")}')
            except:
                pass
        "
      continue-on-error: true

    - name: Debug Framework Detection
      run: |
        echo "ğŸ” Testing framework detection and config flow..."
        python -c "
        import os
        import sys
        import yaml
        sys.path.insert(0, '.')
        
        print('ğŸ”§ Testing framework detection:')
        
        # Load the YAML file
        with open('tests/autogen-agents.yaml', 'r') as f:
            config = yaml.safe_load(f)
            
        print(f'  ğŸ“‹ YAML framework: {config.get(\"framework\", \"NOT_SET\")}')
        print(f'  ğŸ“‹ YAML topic: {config.get(\"topic\", \"NOT_SET\")}')
        
        try:
            from praisonai import PraisonAI
            from praisonai.agents_generator import AgentsGenerator
            
            # Test PraisonAI initialization
            praisonai = PraisonAI(agent_file='tests/autogen-agents.yaml')
            print(f'  ğŸ¯ PraisonAI framework: {praisonai.framework}')
            
            # Test AgentsGenerator initialization
            agents_gen = AgentsGenerator(
                agent_file='tests/autogen-agents.yaml',
                framework=praisonai.framework,
                config_list=praisonai.config_list
            )
            print(f'  âš™ï¸ AgentsGenerator framework: {agents_gen.framework}')
            print(f'  âš™ï¸ Final framework decision: {agents_gen.framework or config.get(\"framework\")}')
            
            # Check config_list
            print(f'  ğŸ”‘ Config list model: {praisonai.config_list[0].get(\"model\")}')
            print(f'  ğŸ”‘ Config list API key: {praisonai.config_list[0].get(\"api_key\", \"NOT_SET\")[:10]}...')
            
        except Exception as e:
            print(f'âŒ Error in framework detection: {e}')
        "
      continue-on-error: true

    - name: Debug PraisonAIModel API Key Flow
      run: |
        echo "ğŸ” Testing PraisonAIModel API key handling..."
        python -c "
        import os
        import sys
        sys.path.insert(0, '.')
        
        print('ğŸ”‘ Environment API Key Check:')
        env_key = os.environ.get('OPENAI_API_KEY', 'NOT_FOUND')
        print(f'  OPENAI_API_KEY: {env_key[:10] if env_key != \"NOT_FOUND\" else \"NOT_FOUND\"}...')
        
        try:
            from praisonai.inc.models import PraisonAIModel
            
            # Test PraisonAIModel with openai/gpt-4o-mini (from YAML)
            model = PraisonAIModel(model='openai/gpt-4o-mini')
            
            print('ğŸ¤– PraisonAIModel Configuration:')
            print(f'  model: {model.model}')
            print(f'  model_name: {model.model_name}')
            print(f'  api_key_var: {model.api_key_var}')
            print(f'  api_key: {model.api_key[:10] if model.api_key != \"nokey\" else \"DEFAULT_NOKEY\"}...')
            print(f'  base_url: {model.base_url}')
            
            if model.api_key == 'nokey':
                print('âŒ FOUND THE ISSUE: PraisonAIModel is using default \"nokey\" instead of environment variable!')
            else:
                print('âœ… PraisonAIModel has valid API key from environment')
                
        except Exception as e:
            print(f'âŒ Error testing PraisonAIModel: {e}')
        "
      continue-on-error: true

    - name: Validate API Key
      run: |
        echo "ğŸ”‘ Testing API key validity with minimal OpenAI call..."
        python -c "
        import os
        try:
            from openai import OpenAI
            client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
            # Make a minimal API call to test key validity
            response = client.models.list()
            print('âœ… API Key is VALID - OpenAI responded successfully')
            print(f'ğŸ“Š Available models: {len(list(response.data))} models found')
        except Exception as e:
            print(f'âŒ API Key is INVALID - Error: {e}')
            print('ğŸ” This explains why all API-dependent tests are failing')
            print('ğŸ’¡ The GitHub secret OPENAI_API_KEY needs to be updated with a valid key')
        "
      continue-on-error: true

    - name: Test Direct PraisonAI Execution
      run: |
        echo "ğŸ§ª Testing direct PraisonAI execution (what works locally)..."
        python -m praisonai tests/autogen-agents.yaml
      continue-on-error: true

    - name: Run Fast Tests
      run: |
        # Run the fastest, most essential tests
        python tests/test_runner.py --pattern fast

    - name: Run Legacy Example Tests
      run: |
        python -m pytest tests/test.py -v --tb=short --disable-warnings
      continue-on-error: true
