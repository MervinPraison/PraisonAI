# -*- coding: utf-8 -*-
"""Forensic_Candidate_Analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18BoZ38TFBDYSvyHbf4xVVcKmVKorIokB

# üß† Candilyzer: Candidate Analyzer for Tech Hiring

Candilyzer is a Streamlit-based application designed to analyze multiple or single candidates based on their GitHub and optionally LinkedIn profiles using AI agents. This notebook adapts the core functionalities of the app for use in Google Colab.

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DhivyaBharathy-web/PraisonAI/blob/main/examples/cookbooks/Forensic_Candidate_Analyzer.ipynb)

## üîê Set Your API Keys
"""

# Install dependencies (do NOT upgrade requests to avoid Colab warning)
!pip install praisonaiagents pygithub exa_py pyyaml --quiet

print("‚úÖ Dependencies installed!")

# üîë Set your API keys here (REQUIRED)
OPENAI_API_KEY = "Enter your openai api key"      # <-- Replace with your OpenAI API key
GITHUB_API_KEY = "Enter your github api key"     # <-- Replace with your GitHub API key
EXA_API_KEY = "Enter your exa api key"        # <-- Replace with your Exa API key

import os
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY  # This is required for PraisonAI

def validate_api_keys():
    missing = []
    if not OPENAI_API_KEY or OPENAI_API_KEY.startswith("sk-..."):
        missing.append("OpenAI")
    if not GITHUB_API_KEY or GITHUB_API_KEY.startswith("ghp_..."):
        missing.append("GitHub")
    if not EXA_API_KEY or EXA_API_KEY.startswith("exa_..."):
        missing.append("Exa")
    if missing:
        raise ValueError(f"‚ùå Please set your API keys for: {', '.join(missing)}")
    print("‚úÖ All API keys are set!")

validate_api_keys()

from praisonaiagents import Agent, Task, PraisonAIAgents
import requests
import json
import re
import yaml
from typing import List, Dict, Any
from github import Github

def github_search_tool(username: str) -> Dict[str, Any]:
    try:
        g = Github(GITHUB_API_KEY)
        user = g.get_user(username)
        repos = user.get_repos()
        repo_data = []
        for repo in repos[:10]:
            repo_info = {
                "name": repo.name,
                "description": repo.description,
                "language": repo.language,
                "stars": repo.stargazers_count,
                "forks": repo.forks_count,
                "created_at": repo.created_at.isoformat(),
                "updated_at": repo.updated_at.isoformat(),
                "is_fork": repo.fork,
                "size": repo.size,
                "open_issues": repo.open_issues_count,
                "default_branch": repo.default_branch,
                "topics": repo.get_topics(),
                "url": repo.html_url
            }
            repo_data.append(repo_info)
        user_data = {
            "username": user.login,
            "name": user.name,
            "bio": user.bio,
            "location": user.location,
            "company": user.company,
            "blog": user.blog,
            "public_repos": user.public_repos,
            "public_gists": user.public_gists,
            "followers": user.followers,
            "following": user.following,
            "created_at": user.created_at.isoformat(),
            "updated_at": user.updated_at.isoformat(),
            "repositories": repo_data
        }
        return user_data
    except Exception as e:
        return {"error": f"Failed to fetch GitHub data: {str(e)}"}

def exa_search_tool(query: str, domains: List[str] = None) -> List[Dict[str, Any]]:
    try:
        headers = {
            "Authorization": f"Bearer {EXA_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "query": query,
            "type": "keyword",
            "text_length_limit": 2000,
            "show_results": True
        }
        if domains:
            data["include_domains"] = domains
        response = requests.post(
            "https://api.exa.ai/search",
            headers=headers,
            json=data
        )
        if response.status_code == 200:
            result = response.json()
            return result.get("results", [])
        else:
            return [{"error": f"Exa API error: {response.status_code}"}]
    except Exception as e:
        return [{"error": f"Failed to search with Exa: {str(e)}"}]

def linkedin_search_tool(profile_url: str = None, name: str = None) -> Dict[str, Any]:
    try:
        if profile_url:
            results = exa_search_tool(f"site:linkedin.com {profile_url}")
        elif name:
            results = exa_search_tool(f"site:linkedin.com {name}")
        else:
            return {"error": "Either profile_url or name must be provided"}
        return {"linkedin_results": results}
    except Exception as e:
        return {"error": f"Failed to search LinkedIn: {str(e)}"}

print("‚úÖ Tools loaded!")

yaml_prompts = """
description_for_multi_candidates: |
  A relentless, forensic-grade technical hiring agent engineered to conduct exhaustive, top-to-bottom audits of candidates‚Äô GitHub repositories and codebases.
  This agent has zero tolerance for fluff, buzzwords, unverifiable claims, or shallow contributions‚Äîonly deeply technical, original, recent, and high-impact work advances.
  Acting as a ruthless data-driven gatekeeper, it filters out all but the absolute elite engineers who demonstrate true mastery and sustained excellence.

instructions_for_multi_candidates: |
  You will perform a forensic, evidence-based evaluation of every candidate‚Äôs GitHub presence and codebase with the following unyielding criteria:
  **Reject all but the top 1-3 engineers who demonstrate irrefutable technical prowess, architectural sophistication, and active leadership.**
  ... (rest of YAML as in your original, or use the full YAML from your repo) ...

description_for_single_candidate: |
  You are a ruthless, elite technical hiring evaluator specializing in deep, forensic analysis of candidates‚Äô digital footprints.
  ... (rest of YAML as in your original, or use the full YAML from your repo) ...

instructions_for_single_candidate: |
  You are an expert-level technical evaluator with zero tolerance for unverifiable claims, shallow work, or misaligned profiles.
  ... (rest of YAML as in your original, or use the full YAML from your repo) ...
"""

data = yaml.safe_load(yaml_prompts)
description_multi = data.get("description_for_multi_candidates", "")
instructions_multi = data.get("instructions_for_multi_candidates", "")
description_single = data.get("description_for_single_candidate", "")
instructions_single = data.get("instructions_for_single_candidate", "")

print("‚úÖ YAML prompts loaded!")

def analyze_single_candidate(github_username: str, job_role: str, linkedin_url: str = None):
    print(f"üîç Analyzing candidate: {github_username} for role: {job_role}")
    try:
        candilyzer_agent = Agent(
            name="Candilyzer",
            role="Single Candidate Analyzer",
            goal="Perform detailed analysis of a single candidate's GitHub and LinkedIn profiles",
            backstory="Expert technical evaluator with forensic analysis capabilities",
            tools=[github_search_tool, exa_search_tool, linkedin_search_tool],
            instructions=instructions_single
        )
        input_text = f"GitHub: {github_username}, Role: {job_role}"
        if linkedin_url:
            input_text += f", LinkedIn: {linkedin_url}"
        analysis_task = Task(
            description=f"Analyze candidate for {job_role}. {input_text}. Provide score and detailed report with final combined analysis",
            expected_output="Comprehensive candidate analysis with score and detailed report",
            agent=candilyzer_agent
        )
        agents = PraisonAIAgents(
            agents=[candilyzer_agent],
            tasks=[analysis_task],
            process="sequential"
        )
        print("ü§ñ AI Evaluation in Progress...")
        result = agents.start()
        print(result)
        score = 0
        match = re.search(r"(\d{1,3})/100", result)
        if match:
            score = int(match.group(1))
            print(f"\n‚≠ê Candidate Score: {score}/100")
        return result
    except Exception as e:
        print(f"‚ùå Error during analysis: {e}")
        return None

def analyze_multiple_candidates(github_usernames: List[str], job_role: str):
    print(f"üîç Analyzing {len(github_usernames)} candidates for role: {job_role}")
    try:
        evaluator_agent = Agent(
            name="StrictCandidateEvaluator",
            role="Technical Hiring Evaluator",
            goal="Conduct forensic analysis of GitHub candidates with strict criteria",
            backstory="Expert in technical evaluation with zero tolerance for unverifiable claims",
            tools=[github_search_tool, exa_search_tool, linkedin_search_tool],
            instructions=instructions_multi
        )
        evaluation_task = Task(
            description=f"Evaluate GitHub candidates for the role '{job_role}': {', '.join(github_usernames)}",
            expected_output="Detailed analysis of each candidate with scores and recommendations",
            agent=evaluator_agent
        )
        agents = PraisonAIAgents(
            agents=[evaluator_agent],
            tasks=[evaluation_task],
            process="sequential"
        )
        print("ü§ñ AI Evaluation in Progress...")
        result = agents.start()
        print(result)
        return result
    except Exception as e:
        print(f"‚ùå Error during analysis: {e}")
        return None

print("‚úÖ Main analysis functions ready!")

# Example: Single candidate
analyze_single_candidate("octocat", "Backend Engineer", linkedin_url=None)

# Example: Multi-candidate
# analyze_multiple_candidates(["octocat", "torvalds"], "Backend Engineer")